{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import comtypes.client as cc\n",
    "import comtypes\n",
    "tlb_id = comtypes.GUID(\"{310BB2DC-AB12-4DE3-839C-1E7CDEAD68A3}\")\n",
    "cc.GetModule((tlb_id, 1, 3))\n",
    "import comtypes.gen.ct_LocateXT_API as LXT_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = r\"C:\\Users\\jame9353\\Box Sync\\Projects\\DCGS-A Message Traffic\\data\\source_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_dates = True #use True or False to search for dates\n",
    "\n",
    "find_polar_UTM_MGRS = False #use True or False to search for polar coordinates\n",
    "\n",
    "#gaz_file_path = r''\n",
    "gaz_file_path = r''\n",
    "fuzzy_percent_error_level = 0 #0 - 30\n",
    "\n",
    "#ca_file_path = r''\n",
    "ca_file_path = r''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(file):\n",
    "    ICoordSearch = cc.CreateObject(LXT_API.CoordinateSearching,None,None,LXT_API.ICoordinateSearching2)\n",
    "    ICoordSearch.UTM_NorthPolar = find_polar_UTM_MGRS\n",
    "    ICoordSearch.UTM_SouthPolar = find_polar_UTM_MGRS\n",
    "    ICoordSearch.MGRS_NorthPolar = find_polar_UTM_MGRS\n",
    "    ICoordSearch.MGRS_SouthPolar = find_polar_UTM_MGRS\n",
    "  \n",
    "    ILxtMgr = cc.CreateObject(LXT_API.LocateXT_Manager2, None, None, LXT_API.ILocateXT_Manager3)\n",
    "    ILxtMgr.SetSearcher(ICoordSearch)\n",
    "  \n",
    "\n",
    "    if find_dates:\n",
    "        IDateSearch = cc.CreateObject(LXT_API.DateSearching,None,None,LXT_API.IDateSearching)\n",
    "        ILxtMgr.SetSearcher(IDateSearch)\n",
    "\n",
    "    if gaz_file_path:\n",
    "        #print(\"gaz: \",gaz_file_path,\" err: \",fuzzy_percent_error_level)\n",
    "        IGazSearch = cc.CreateObject(LXT_API.GazetteerSearching,None,None,LXT_API.IGazetteerSearching)\n",
    "        IGazSearch.GazetteerFile = os.path.abspath(gaz_file_path)\n",
    "        IGazSearch.FuzzyErrorLevelPercent= fuzzy_percent_error_level\n",
    "        ILxtMgr.SetSearcher(IGazSearch)\n",
    "\n",
    "    if ca_file_path:\n",
    "        #print(\"ca: \",ca_file_path)\n",
    "        ICASearch = cc.CreateObject(LXT_API.CustomAttributeSearching,None,None,LXT_API.ICustomAttributeSearching)\n",
    "        ICASearch.CustomAttributesFile = os.path.abspath(ca_file_path)\n",
    "        ILxtMgr.SetSearcher(ICASearch)\n",
    "\n",
    "    out_path = os.path.abspath (path_to_output)\n",
    "\n",
    "    #loop until the file can be opened exclusively\n",
    "    #this ensures the file is done being written/copied\n",
    "    #and can be processed further\n",
    "    success = False\n",
    "    count = 0\n",
    "    while not success and count < 20:\n",
    "        try:\n",
    "            hFile = win32file.CreateFile (\n",
    "                      full_filename,\n",
    "                      win32con.GENERIC_READ | win32con.GENERIC_WRITE,\n",
    "                      0,#exclusive access\n",
    "                      None,\n",
    "                      win32con.OPEN_EXISTING,\n",
    "                      win32con.FILE_ATTRIBUTE_NORMAL,\n",
    "                      None\n",
    "                    )\n",
    "\n",
    "        except:\n",
    "             #print(\"Unexpected error:\", sys.exc_info()[1])\n",
    "             #raise\n",
    "            pass\n",
    "        else:\n",
    "            #print(\"handle = \", hFile)\n",
    "            win32api.CloseHandle(hFile)\n",
    "            success = True\n",
    "\n",
    "        count += 1\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        if success:\n",
    "            #file can be processed\n",
    "            print(\"Processing: \",file)\n",
    "            csvOut = ILxtMgr.Scan(LXT_API.lxtInputTypeFilename, file, LXT_API.lxtOutputTypeCSV)\n",
    "            csvOutAscii = re.sub(r'[^\\x00-\\x7f]',r' ',csvOut)#replace every character NOT in 0x00 - 0x7f with space\n",
    "            #print(csvOutAscii)\n",
    "            #eliminate embedded carriage returns\n",
    "            csvByteArray = bytearray(csvOutAscii,'ascii','replace')#also replaces every char NOT ASCII, but with '?'\n",
    "            insideQuotes = False\n",
    "            i = 0\n",
    "            while i < (len(csvByteArray) - 1):\n",
    "            #if i < 100:\n",
    "            #  print(\"processing i = \",i,\"  : \",csvByteArray[i],\"\\n\")\n",
    "                if insideQuotes:\n",
    "                  #print(\"insideQuotes\\n\")\n",
    "                    if 34 == csvByteArray[i]:\n",
    "                        if 34 != csvByteArray[i+1]:\n",
    "                            insideQuotes = False\n",
    "                        else:\n",
    "                              i += 1\n",
    "                    elif (13 == csvByteArray[i]) or (10 == csvByteArray[i]):\n",
    "                        csvByteArray[i] = 32\n",
    "                elif 34 == csvByteArray[i]:\n",
    "                    insideQuotes = True\n",
    "                #while loop last\n",
    "                i += 1\n",
    "      \n",
    "            #write file\n",
    "            #print(csvByteArray)      \n",
    "            fd, tmpName = tempfile.mkstemp(\".csv\",re.sub(r'[\\/:*?\"<>|]',r'_',str(datetime.datetime.now())),out_path,True)\n",
    "            os.write(fd,csvByteArray)\n",
    "            os.close(fd)\n",
    "            print(\"Output: \",tmpName)\n",
    "             \n",
    "\n",
    "    \n",
    "    print(\"exiting thread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tacelint(text, intermediate_file):\n",
    "\n",
    "    \n",
    "    arcpy.conversion.ExtractLocationsText(coords, \n",
    "                                      intermediate_file, \n",
    "                                      None, \"FIND_DD_LATLON\", \"FIND_DD_XYDEG\", \"FIND_DD_XYPLAIN\", \"FIND_DM_LATLON\", \n",
    "                                      \"FIND_DM_XYMIN\", \"FIND_DMS_LATLON\", \"FIND_DMS_XYSEC\", \"FIND_DMS_XYSEP\", \n",
    "                                      \"FIND_UTM_MAINWORLD\", \"DONT_FIND_UTM_NORTHPOLAR\", \"DONT_FIND_UTM_SOUTHPOLAR\", \n",
    "                                      \"FIND_MGRS_MAINWORLD\", \"DONT_FIND_MGRS_NORTHPOLAR\", \"DONT_FIND_MGRS_SOUTHPOLAR\", \n",
    "                                      \"USE_DOT_DECIMAL_MARK\", \"PREFER_LATLON\", \"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 11258999068426.2;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision\", \n",
    "                                      None, \"DONT_USE_FUZZY\", None, None, \"FIND_DATE_MONTHNAME\", \"FIND_DATE_M_D_Y\", \"FIND_DATE_YYYYMMDD\", \n",
    "                                      \"FIND_DATE_YYMMDD\", \"FIND_DATE_YYJJJ\", None, None, None, None, \n",
    "                                      None, None, None, 254, 254, \"STD_COORD_FMT_DD\")\n",
    "    \n",
    "    if arcpy.Exists(intermediate_file) == True:\n",
    "        result = arcpy.GetCount_management(intermediate_file)\n",
    "        if int(result[0]) >0:\n",
    "            fields = [f.name for f in arcpy.ListFields(intermediate_file)]\n",
    "            with arcpy.da.SearchCursor(intermediate_file, fields) as cursor:\n",
    "                for row in cursor:\n",
    "                    shape = row[0]\n",
    "                \n",
    "                    return shape\n",
    "        else:\n",
    "            return \"No valid coordinates extracted\", 0, 0\n",
    "    else:\n",
    "        return \"No valid coordinates extracted\", 0, 0\n",
    "    \n",
    "    del intermediate_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added:  example1.txt, example2.txt, example3.txt, example4.txt, recexrep.txt, tacrep1.txt, tacrep2.txt, tacrep3.txt, tacrep4.txt, tacrep5.txt\n",
      "EXER BRAVE SHIELD 93\n",
      "UNCLASSIFIED USA 20090214T132530Z\n",
      "060812Z 060821Z HIGHBLOW 3R456\n",
      "(-79.02380555555555, 35.17369444444438) 35NM 35NM\n",
      "060942Z 060821Z ROUNDFACE 3R456\n",
      "(-94.01169396025898, 38.95563519524666) 25KM 100KM\n",
      "Processed 1 files...\n",
      "Processed 2 files...\n",
      "OPER WET BIRD\n",
      "UNCLASSIFIED USA 20090214T132530Z\n",
      "311015Z 312020Z SOFTBALL -\n",
      "(-1.404583333333278, 52.22924999999998) 12.1NM 25.6NM\n",
      "Processed 3 files...\n",
      "EXER BRAVE SHIELD 93\n",
      "UNCLASSIFIED USA 20090214T132530Z\n",
      "060812Z 060821Z HIGHBLOW 3R456\n",
      "(-79.02380555555555, 35.17369444444438) 35NM 35NM\n",
      "060942Z 060821Z ROUNDFACE 3R456\n",
      "('No valid coordinates extracted', 0, 0) 25KM 100KM\n",
      "Processed 4 files...\n",
      "EXER BLACK PIG\n",
      "UNCLASSIFIED USA 20090214T132530Z\n",
      "I GE CORPS Z198A\n",
      "Processed 5 files...\n",
      "Processed 6 files...\n",
      "Processed 7 files...\n",
      "Processed 8 files...\n",
      "Processed 9 files...\n",
      "Processed 10 files...\n",
      "Exiting\n"
     ]
    }
   ],
   "source": [
    "# Function to watch a folder and detect new images on a 1 second refresh interval\n",
    "#before = dict ([(f, None) for f in os.listdir (text_file)])\n",
    "before = {}\n",
    "count = 0\n",
    "errors = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    # Compares the folder contents after the sleep to what existed beforehand, and makes a list of adds and removes\n",
    "    after = dict ([(f, None) for f in os.listdir (text_file)])\n",
    "    added = [f for f in after if not f in before]\n",
    "    removed = [f for f in before if not f in after]\n",
    "\n",
    "    if added: print(\"Added: \", \", \".join (added))\n",
    "    if removed: print(\"Removed: \", \", \".join (removed))\n",
    "    before = after\n",
    "\n",
    "    for file in added:\n",
    "        if file.endswith(\".txt\"):\n",
    "            count +=1\n",
    "            with open(os.path.join(text_file, file), mode='r') as file:\n",
    "                tacelint = file.read()\n",
    "                lines = tacelint.split(\"\\n\")\n",
    "                if lines[1].startswith(\"MSGID/\"):\n",
    "                    msg_type = lines[1].split(\"/\")[1]\n",
    "                    if msg_type == 'TACELINT'or msg_type == 'RECCEXREP':\n",
    "                        for line in lines:\n",
    "                            int_file = \"in_memory/tacelint_file\"\n",
    "                            split_line = line.split(\"/\")\n",
    "                            if line.startswith(\"SOI/\"):\n",
    "                                date_obs = split_line[2]\n",
    "                                date_rep = split_line[3]\n",
    "                                asset = split_line[5]\n",
    "                                reference = split_line[7]\n",
    "                                print(date_obs, date_rep, asset, reference)\n",
    "                            elif line.startswith(\"EMLOC/\"):\n",
    "                                coords = split_line[3].split(\":\")[1]\n",
    "    \n",
    "                                if len(split_line) == 7:\n",
    "                                    semiminor = split_line[4]\n",
    "                                    semimajor = split_line[4]\n",
    "                                if len(split_line) == 10:\n",
    "                                    semiminor = split_line[7]\n",
    "                                    semimajor = split_line[6]\n",
    "                                \n",
    "                                point = extract_tacelint(coords, int_file)\n",
    "                                if type(point) == tuple:\n",
    "                                    print(point, semiminor, semimajor)\n",
    "                                else:\n",
    "                                    print(point)\n",
    "                                #except:\n",
    "                                    #print(\"Error processing data, passing...\")\n",
    "                            elif line.startswith('EXER/') or line.startswith('OPER/'):\n",
    "                                op_type = split_line[0]\n",
    "                                op_name = split_line[1]\n",
    "                                print(op_type, op_name)\n",
    "                            \n",
    "                            elif line.startswith('/'):\n",
    "                                if len(split_line) == 8:\n",
    "                                    if msg_type == 'TACELINT' or msg_type == 'RECCEXREP':\n",
    "                                        classification = split_line[5]\n",
    "                                        orig_country = split_line[4]\n",
    "                                        msg_dt = split_line[1]\n",
    "                                        print(classification, orig_country, msg_dt)\n",
    "                            elif line.startswith('MISSNID/'):\n",
    "                                unit = split_line[2]\n",
    "                                unit_code = split_line[5]\n",
    "                                print(unit, unit_code)\n",
    "                        \n",
    "                            if arcpy.Exists(int_file) == True:\n",
    "                                arcpy.Delete_management(int_file)\n",
    "                                \n",
    "        print(\"Processed \" + str(count) + \" files...\")\n",
    "                                \n",
    "    if count == 10:\n",
    "        print(\"Exiting\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.Delete_management(\"in_memory/tacelint_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.Exists(\"in_memory/tacelint_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to create process using 'C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\python.exe \"C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Scripts\\pip-script.py\" install comtypes'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: comtypes in c:\\programdata\\anaconda3\\lib\\site-packages (1.1.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install comtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
